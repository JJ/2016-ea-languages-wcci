\documentclass[sigconf]{acmart}
%%% Local Variables:
%%% ispell-local-dictionary: "english"
%%% End:

\usepackage[utf8]{inputenc}
\usepackage{booktabs} % For formal tables
\usepackage{graphicx}
\usepackage{rotating}
\usepackage{listings}

\definecolor{Gray}{gray}{0.6}

\setcopyright{rightsretained}

% DOI
\acmDOI{10.1145/nnnnnnn.nnnnnnn}

% ISBN
\acmISBN{978-x-xxxx-xxxx-x/YY/MM}


%Conference
\acmConference[GECCO '18]{the Genetic and Evolutionary Computation
Conference 2018}{July 15--19, 2018}{Kyoto, Japan}
\acmYear{2018}
\copyrightyear{2018}


\acmArticle{4}
\acmPrice{15.00}

\begin{document}


<<setup, cache=FALSE,echo=FALSE>>=
library("ggplot2")
library("RColorBrewer")
measures.mo <- read.csv('measures-maxones-2018.csv',header=TRUE,sep=",",dec=".")
measures.bf <- read.csv('measures-bitflip-2018.csv',header=TRUE,sep=",",dec=".")
measures.xo <- read.csv('measures-xover-2018.csv',header=TRUE,sep=",",dec=".")
measures.perl6 <- read.csv('measures-maxones-perl6.csv',header=TRUE,sep=",",dec=".")
@

\title{Performance improvements of evolutionary algorithms in Perl 6} 

\author{Juan-Julián Merelo-Guervós}
\orcid{1234-5678-9012}
\affiliation{%
  \institution{Universidad de Granada}
  \streetaddress{Daniel Saucedo Aranda, s/n}
  \city{Granada}
  \country{Spain}
}
\email{jmerelo@ugr.es}

% The default list of authors is too long for headers.
%\renewcommand{\shortauthors}{J. J. Merelo et al.}

\begin{abstract}
  
  Perl 6 is a recently released language that belongs to the Perl family but has
  actually been designed from scratch. Through its two-year old
  (released) history, it has increased performance in several orders
  of magnitude, arriving recently to the point where it can be safely
  used in production. In this paper, we are going to compare the
  historical and current performance of Perl 6 in a single problem,
  OneMax, to those of other interpreted languages; besides, we will
  also use implicit concurrency and see what kind of performance and
  scaling can we expect from it.  

\end{abstract}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003752.10003809.10003716.10011136.10011797.10011799</concept_id>
<concept_desc>Theory of computation~Evolutionary algorithms</concept_desc>
<concept_significance>500</concept_significance>
</concept>

<concept>
<concept_id>10010520.10010521.10010537.10003100</concept_id>
<concept_desc>Computer systems organization~Cloud computing</concept_desc>
<concept_significance>500</concept_significance>
</concept>

<concept>
<concept_id>10010147.10010919.10010172</concept_id>
<concept_desc>Computing methodologies~Distributed algorithms</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Theory of computation~Evolutionary algorithms}

\ccsdesc[300]{Computing methodologies~Distributed algorithms}

\keywords{Benchmarking, computer languages, concurrency, evolutionary
  algorithms, Perl, Perl 6}

\maketitle


\section{Introduction}

Performance has always been a concern in scientific
computing. Generally, you will want to use the fastest language
available to be able to run your experiments in as little time as
possible. However, while implementation matters
\cite{DBLP:conf/iwann/MereloRACML11}, ease of programming, available
libraries and supporting community are sometimes bigger concerns,
since in scientific computing the target is to optimize
time-to-publish the paper, not only time from pressing {\em Enter} to
obtaining the results, and that includes time to get toe program done
itself, as well as process results.

In that sense, interpreted languages such as Python, Perl or JavaScript
\cite{fortin2012deap,DBLP:conf/ijcci/FarisAMCM16,DBLP:conf/gecco/GuervosVGES14,perl-ea,hidaka2017development,rivas2014object,ae09}
offer fast prototyping, if not the fastest implementation, which
usually belongs to compiled languages such as Haskell or Java
\cite{DBLP:conf/evoW/MereloCBRGFRV16}. However, as proved in the cited
paper, that is not always the case and new languages deserve a chance
to be tested, mainly if they offer functionalities that might make the
implementation of evolutionary algorithms faster or more straightforward.

Besides, performance in a language is not a static thing; while some
languages are happy enough with the level they achieve and focus on
other functionalities, newer languages focus on performance in every
new release, offering improvements of several orders of
magnitude. This has been the case of Perl 6
\cite{Tang:2007:PRI:1190216.1190218}, a new, concurrent, dynamic and
multi-paradigm language that has been in development since 2000 and
released in December 2015. Since then, it has had a release cycle of
one, or sometimes more, releases every month, with stable releases
every four months. While initial tests discouraged us from including
its figures in the paper where we benchmarked many languages for
evolutionary algorithms \cite{DBLP:conf/evoW/GuervosBCRGRVHR17}, the
increase in performance has been continuous, as well as the
implementation of implicit paralellism features. 

This paper is specially focused on benchmarking this language for
evolutionary algorithms, with the intention of proposing it as
production-ready in a scientific computing or evolutionary computation
experiment. 

The rest of the paper is organized as follows. We will briefly present
the state of the art in benchmarking evolutionary algorithms in the
next section, followed by the set of experiments used to test
performance in Section \ref{sec:exp}. Results and charts will be
presentes in Section \ref{sec:res}, and we will close the paper by
stating our conclusions. 

\section{State of the art}
\label{sec:soa}

As a matter of fact, there is very little scientific literature on
Perl 6, much less applied to scientific computing. The paper by Audrey
Tang \cite{Tang:2007:PRI:1190216.1190218}, one of the early
programmers of a Perl 6 compiler in Haskell called Pugs, is one of the
few we can find. In fact, the paper where she describes the design of
the language has had some influence in language design, including the
design of Typed Scheme, a functional language \cite{tobin2008design}. 

Its sister language, Perl, has been used for a long time in
Evolutionary Algorithms, with an early tool but
used for minimizing the performance of a network
\cite{bucur2016optimizing}. Since the publication of the {\tt
  Algorithm::Evolutionary} library circa 2002
\cite{ecperl,perl-ea} it has been applied to many different problems,
including solving the MasterMind puzzle \cite{DBLP:journals/evi/Maestro-MontojoSG14}. 
In fact, its speed processing evolutionary
algorithms has made it a great tool for evolving regular expressions
via the DiscoverRegex and GenRegex tools \cite{ruano2018using},  and
even optimizing the yield of analog integrated circuits \cite{guerra2015ocba}. 

Perl 5 was a convenient and multi-paradigm, if not particularly
groundbreaking language. Conceptually, you could program an
evolutionary algorithm in pretty much the same way you would do it in
C or C++, which were at the time much faster languages. The fact that
it was used  proves that languages for implementing evolutionary
algorithms are not chosen purely on its raw speed. 

However, speed has to be adequate and not vary in orders of magnitude
with respect to other, well-establishe, language. Even if slower, the
trade-off might be interesting if a new language offers new ways of
implementing evolutionary algorithms that give you some insight on the
inner working of evolutionary optimization. This why in this paper we
will set to measure the speed of Perl 6 and its evolution, in order to
prove that it has come the time to consider it as a language for
evolutionary optimization given the functional and concurrent
facilities it offers. 

\section{Experimental setup}
\label{sec:exp}

In this experiment we have used the same operators and data already
published in \cite{DBLP:conf/evoW/MereloCBRGFRV16} that is, crossover,
mutation and one-max or count-ones. We have added the Royal Road
function \cite{mitchell1992royal}, mainly with the objective of
comparing Perl and Perl 6 and its parallel facilities. 

The functions are well known, and the main objective of these tests
was, besides comparing performance side by side, see how this
performance scales to big, and a bit unrealistic, chromosome
sizes. The way the handling of data structures by particular languages
is done makes that, sometimes, the speed of dealing with bigger sizes
be bigger than with smaller sizes; as a matter of fact, in the above
mentioned paper Java achieved its best performance for the biggest
size. 

We tested several data structures in Perl 6 and finally chose a vector
(or array) of booleans as the fastest one. In fact the speed of the
benchmark is divided in two parts: speed for randomly generating the
vector and speed of actually counting the number of ones. In this
case, generating a vector of {\tt Bool}s was considerably faster than
doing the same with integers, although summing them was almost 4 times
as slow. That is why we also test a vector of integers in the
experiments we show below. These two operations take two lines in Perl
6, as follows.

\begin{lstlisting}[language=Perl]
my $ones = Bool.roll xx $len ;
my $maxones = $ones.sum;	
\end{lstlisting}

These two lines show the advantage of this kind of language; the same
operation needs several lines and two loops in most other,
non-functional, languages. The first one creates an array of random
boolean values, generated with {\tt Bool.roll}; {\tt xx} {\em
  multiplies} by the length to yield an array of the desired
length. And the second line just uses the {\tt sum} method, which is
an standard method for arrays and can also be applied to arrays of
booleans. In Perl 6, there are many possible ways of achieving the
same, but in fact after several measurements we found this was the
fastest, even if initially it was much slow than for other
languages. Also, as it can be seen, Perl 6 uses {\em sigils} for
variables, this {\tt \$} been applied to most kinds of containers. {\tt
  Bool} is a standar type, and {\tt my} is a {\em scope} declaration
which can optionally include a type or class declaration. A fuller
introduction to the language is outside the scope of this paper, but
the interested reader can check the documentation at
\url{https://docs.perl.org} for a tutorial or a more thorough
explanation of all its features and capabilities. 

The benchmark consists in 100,000 repetitions of the operation for
sizes that increase by 2 from 16 to, when possible, 32768. All
experiments took place in a desktop computer with 8 cores running
Ubuntu 14.04.5.

All programs are open source, and included in the same repository that
holds this paper, as well as the repository in GitHub
\url{https://github.com/JJ/perl6eo}. Data from the experiments is also
freely available from the repository that holds this paper. 

\section{Results and analysis}
\label{sec:res}
%
\begin{figure}[h!tb]
  \centering
<<results-perl6, cache=FALSE,echo=FALSE>>=
getPalette = colorRampPalette(brewer.pal(9, "Set1"))
colourCount = length(unique(measures.perl6$Version))
ggplot(measures.perl6,aes(x=length,y=time,colour=factor(Version)))+ geom_line() + geom_point()  + ggtitle("Perl6 language benchmarks: Onemax") + scale_y_log10()+scale_x_log10() + scale_color_manual(name='Language',values=getPalette(colourCount)) + theme( legend.text=element_text(size=10))
@
\caption{Plot of time needed to perform 100K OneMax evaluations in
 several versions of Perl 6, from 2016 to the current one in 2018.
 Strings have 
lengths increasing by a factor of two from 16 to $2^{15}$. Please note
that $x$ and $y$ both have a logarithmic scale.}
\label{fig:perl6:mo}
\end{figure}
%

The first experiment just measured the speed of the {\sf max-ones}
function across releases of Perl 6; Perl 6 has a monthly release
schedule, with version number corresponding to year and month. The
result of this operation is shown in Figure \ref{fig:perl6:mo}, and it
clearly shows the increase in speed across time, that amounts to
almost one order of magnitude from the first version, with a
performance that prompted us to exclude it from our initial study, to
the current, which is much better. 
%
\begin{figure*}[h!tb]
  \centering
<<results-mo, cache=FALSE,echo=FALSE>>=
colourCount = length(unique(measures.mo$languagerepresentation))
ggplot(measures.mo,aes(x=length,y=time,colour=factor(languagerepresentation)))+ geom_line() + geom_point()  + ggtitle("Evolutionary algorithm language benchmarks: Onemax") + scale_y_log10()+scale_x_log10() + scale_color_manual(name='Language',values=getPalette(colourCount)) + theme( legend.text=element_text(size=10))
@
\caption{Plot of time needed to perform 100K OneMax evaluations in strings with
lengths increasing by a factor of two from 16 to $2^{15}$. Please note
that $x$ and $y$ both have a logarithmic scale.}
\label{fig:time:mo}
\end{figure*}
%

Despite the improvement, it needs to be compared to the rest of the
languages we tested in the previous paper. We have excluded the
fastest, mainly compiled, languages, to leave mainly scripting, and
some compiled, languages. This comparison is shown in Figure
\ref{fig:time:mo}. 

%
\begin{figure*}[h!tb]
  \centering
<<results-bf, cache=FALSE,echo=FALSE>>=
colourCount = length(unique(measures.bf$languagerepresentation))
ggplot(measures.bf,aes(x=length,y=time,colour=factor(languagerepresentation)))+ geom_line() + geom_point()  + ggtitle("Evolutionary algorithm language benchmarks: Bitflip mutation") + scale_y_log10()+scale_x_log10() + scale_color_manual(name='Language',values=getPalette(colourCount)) + theme( legend.text=element_text(size=10))
@
\caption{Plot of time needed to perform mutation on  100K chromosomes
 with increasing lengths from 16 to $2^{15}$. Please note
that $x$ and $y$ both have a logarithmic scale.}
\label{fig:time:mo}
\end{figure*}
%
%
\begin{figure*}[h!tb]
  \centering
<<results-xo, cache=FALSE,echo=FALSE>>=
colourCount = length(unique(measures.bf$languagerepresentation))
ggplot(measures.xo,aes(x=length,y=time,colour=factor(languagerepresentation)))+ geom_line() + geom_point()  + ggtitle("Evolutionary algorithm language benchmarks: Crossover") + scale_y_log10()+scale_x_log10() + scale_color_manual(name='Language',values=getPalette(colourCount)) + theme( legend.text=element_text(size=10))
@
\caption{Plot of time needed to perform crossover on 100K chromosomes
 with increasing lengths from 16 to $2^{15}$. Please note
that $x$ and $y$ both have a logarithmic scale.}
\label{fig:time:mo}
\end{figure*}
%
\section{Conclusions}

\section*{Acknowledgements}

This paper is part of the open science effort at the university of
Granada. It has been written using {\tt knitr}, and its source as well as
the data used to create it can be downloaded from 
\href{https://github.com/JJ/2016-ea-languages-wcci}{the GitHub
  repository} \url{https://github.com/JJ/2016-ea-languages-wcci/}. 
It has been supported in part by
\href{http://geneura.wordpress.com}{GeNeura Team}, 
projects TIN2014-56494-C4-3-P (Spanish Ministry of Economy and Competitiveness),
project 5622.15-P from Tecnol{\'o}gico Nacional de M{\'exico}.  


\bibliographystyle{ACM-Reference-Format}
\bibliography{geneura,languages,GA-general}

\end{document}


%%% Local Variables:
%%% ispell-local-dictionary: "english"
%%% hunspell-local-dictionary: "english"
%%% End:
